{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Fatigue\n",
    "- GitHub [link](https://github.com/romainmartinez/fatigue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todos\n",
    "- onehot encoding\n",
    "- feature importance in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('.', 'data/')\n",
    "DATA_FILE = 'DatabaseRPT.mat'\n",
    "mat = sio.loadmat(os.path.join(DATA_PATH, DATA_FILE))['DataBaseRPT'][0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label\n",
    "    - `Y` (1, 162): 1 = prefatigue, 2 = fatigue\n",
    "\n",
    "- used features\n",
    "    - `AllX` (24, 162): 24 (6 DoF x 4 variables) x 162 (81 participants x 2 time points).\n",
    "    - `CAssignAll` (1, 24): AllX column assignment\n",
    "\n",
    "    - `Sex` (1, 162)\n",
    "    - `Endurance` (1, 162)\n",
    "\n",
    "- not used\n",
    "    - `BestX` (7, 162): 7 (variables with SRM>0.8) x 162 (81 participants x 2 time points) matrix. Contains data only for the most responsive variables (SRM>0.8).\n",
    "    - `CAssignBest` (1, 7): BestX column assignment.\n",
    "    - `Age` (1, 162): too much NaN.\n",
    "    - `Height` (1, 162): too much NaN.\n",
    "    - `Weight` (1, 162) Too much NaN.\n",
    "    - `SubjectKey` (1, 162): useless.\n",
    "    - `SID` (1, 162): useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [i[0] for i in mat['CAssignAll'].flatten()]\n",
    "# find variable with SRM > .8\n",
    "srm_names = np.array([i[0] for i in mat['CAssignBest'].flatten()])\n",
    "srm_idx = np.in1d(col_names, srm_names)\n",
    "\n",
    "# add `AllX`\n",
    "X = mat['AllX'].T\n",
    "\n",
    "# add `Sex`\n",
    "X = np.c_[X, mat['Sex'].T]\n",
    "col_names.append('Sex')\n",
    "\n",
    "# add `Endurance`\n",
    "X = np.c_[X, mat['Endurance'].T]\n",
    "col_names.append('Endurance')\n",
    "\n",
    "col_names = np.array(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mat['Y'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data & shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data & shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveElbFlexMean</th>\n",
       "      <th>ROMElbFlexMean</th>\n",
       "      <th>AveElbFlexSD</th>\n",
       "      <th>ROMElbFlexSD</th>\n",
       "      <th>AveShPlaneMean</th>\n",
       "      <th>ROMShPlaneMean</th>\n",
       "      <th>AveShPlaneSD</th>\n",
       "      <th>ROMShPlaneSD</th>\n",
       "      <th>AveShEleMean</th>\n",
       "      <th>ROMShEleMean</th>\n",
       "      <th>...</th>\n",
       "      <th>AveTrYMean</th>\n",
       "      <th>ROMTrYMean</th>\n",
       "      <th>AveTrYSD</th>\n",
       "      <th>ROMTrYSD</th>\n",
       "      <th>AveTrZMean</th>\n",
       "      <th>ROMTrZMean</th>\n",
       "      <th>AveTrZSD</th>\n",
       "      <th>ROMTrZSD</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Endurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105.983144</td>\n",
       "      <td>63.339618</td>\n",
       "      <td>2.219401</td>\n",
       "      <td>1.794134</td>\n",
       "      <td>23.518597</td>\n",
       "      <td>13.624799</td>\n",
       "      <td>1.338393</td>\n",
       "      <td>2.357813</td>\n",
       "      <td>80.274017</td>\n",
       "      <td>2.942674</td>\n",
       "      <td>...</td>\n",
       "      <td>16.382423</td>\n",
       "      <td>13.629558</td>\n",
       "      <td>1.112671</td>\n",
       "      <td>1.977798</td>\n",
       "      <td>-0.550047</td>\n",
       "      <td>2.671822</td>\n",
       "      <td>0.228494</td>\n",
       "      <td>0.711787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.166216</td>\n",
       "      <td>61.875226</td>\n",
       "      <td>2.239310</td>\n",
       "      <td>2.548458</td>\n",
       "      <td>22.851141</td>\n",
       "      <td>11.726534</td>\n",
       "      <td>1.182490</td>\n",
       "      <td>1.401127</td>\n",
       "      <td>77.897777</td>\n",
       "      <td>4.062635</td>\n",
       "      <td>...</td>\n",
       "      <td>16.041630</td>\n",
       "      <td>15.078508</td>\n",
       "      <td>0.910697</td>\n",
       "      <td>1.003788</td>\n",
       "      <td>-0.208865</td>\n",
       "      <td>1.242553</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.496108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.914284</td>\n",
       "      <td>60.930029</td>\n",
       "      <td>1.482458</td>\n",
       "      <td>1.167593</td>\n",
       "      <td>27.289316</td>\n",
       "      <td>12.291697</td>\n",
       "      <td>1.223189</td>\n",
       "      <td>2.452705</td>\n",
       "      <td>83.932823</td>\n",
       "      <td>2.886935</td>\n",
       "      <td>...</td>\n",
       "      <td>15.039772</td>\n",
       "      <td>14.311074</td>\n",
       "      <td>0.979720</td>\n",
       "      <td>2.070705</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.934767</td>\n",
       "      <td>0.488540</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.066549</td>\n",
       "      <td>59.524098</td>\n",
       "      <td>2.364182</td>\n",
       "      <td>1.849991</td>\n",
       "      <td>23.083816</td>\n",
       "      <td>7.519415</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>3.503819</td>\n",
       "      <td>78.701025</td>\n",
       "      <td>2.997990</td>\n",
       "      <td>...</td>\n",
       "      <td>16.070120</td>\n",
       "      <td>16.178023</td>\n",
       "      <td>1.418294</td>\n",
       "      <td>3.521951</td>\n",
       "      <td>-0.544067</td>\n",
       "      <td>1.885480</td>\n",
       "      <td>0.610577</td>\n",
       "      <td>0.851287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.259333</td>\n",
       "      <td>81.531138</td>\n",
       "      <td>2.610755</td>\n",
       "      <td>3.632922</td>\n",
       "      <td>42.387152</td>\n",
       "      <td>27.789377</td>\n",
       "      <td>1.605530</td>\n",
       "      <td>2.027628</td>\n",
       "      <td>71.280986</td>\n",
       "      <td>8.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>8.908385</td>\n",
       "      <td>8.815273</td>\n",
       "      <td>0.709582</td>\n",
       "      <td>1.250228</td>\n",
       "      <td>-0.123442</td>\n",
       "      <td>1.065910</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveElbFlexMean  ROMElbFlexMean  AveElbFlexSD  ROMElbFlexSD  AveShPlaneMean  \\\n",
       "0      105.983144       63.339618      2.219401      1.794134       23.518597   \n",
       "1      106.166216       61.875226      2.239310      2.548458       22.851141   \n",
       "2      100.914284       60.930029      1.482458      1.167593       27.289316   \n",
       "3      105.066549       59.524098      2.364182      1.849991       23.083816   \n",
       "4       93.259333       81.531138      2.610755      3.632922       42.387152   \n",
       "\n",
       "   ROMShPlaneMean  AveShPlaneSD  ROMShPlaneSD  AveShEleMean  ROMShEleMean  \\\n",
       "0       13.624799      1.338393      2.357813     80.274017      2.942674   \n",
       "1       11.726534      1.182490      1.401127     77.897777      4.062635   \n",
       "2       12.291697      1.223189      2.452705     83.932823      2.886935   \n",
       "3        7.519415      1.510000      3.503819     78.701025      2.997990   \n",
       "4       27.789377      1.605530      2.027628     71.280986      8.000008   \n",
       "\n",
       "     ...      AveTrYMean  ROMTrYMean  AveTrYSD  ROMTrYSD  AveTrZMean  \\\n",
       "0    ...       16.382423   13.629558  1.112671  1.977798   -0.550047   \n",
       "1    ...       16.041630   15.078508  0.910697  1.003788   -0.208865   \n",
       "2    ...       15.039772   14.311074  0.979720  2.070705    0.096174   \n",
       "3    ...       16.070120   16.178023  1.418294  3.521951   -0.544067   \n",
       "4    ...        8.908385    8.815273  0.709582  1.250228   -0.123442   \n",
       "\n",
       "   ROMTrZMean  AveTrZSD  ROMTrZSD  Sex  Endurance  \n",
       "0    2.671822  0.228494  0.711787  2.0        2.0  \n",
       "1    1.242553  0.541000  0.496108  2.0        2.0  \n",
       "2    0.934767  0.488540  0.317386  2.0        8.0  \n",
       "3    1.885480  0.610577  0.851287  2.0        8.0  \n",
       "4    1.065910  0.415764  0.404298  2.0        4.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X, columns=col_names).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom class\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# decomposition\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "\n",
    "# scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# other\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, selection='raw', idx=srm_idx):\n",
    "        self.selection = selection\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.selection == 'raw':\n",
    "            output = X\n",
    "        elif self.selection == 'idx':\n",
    "            output = X[:, srm_idx]\n",
    "        return output\n",
    "\n",
    "class Scale(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy='raw'):\n",
    "        self.strategy = strategy\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        if self.strategy == 'raw':\n",
    "            scaler = None\n",
    "        elif self.strategy == 'standardscaler':\n",
    "            scaler = StandardScaler()\n",
    "        \n",
    "        if scaler is None:\n",
    "            output = X_copy\n",
    "        else:\n",
    "            output = scaler.fit_transform(X_copy)\n",
    "        return output\n",
    "\n",
    "class Decomposition(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy='raw', N=None):\n",
    "        self.strategy = strategy\n",
    "        self.N = N\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.strategy == 'raw':\n",
    "            decomposer = None\n",
    "            output = X\n",
    "        elif self.strategy == 'pca':\n",
    "            decomposer = PCA(iterated_power=7, n_components=self.N)\n",
    "            output = decomposer.fit_transform(X)\n",
    "        return output\n",
    "    \n",
    "def get_categorical_cols(X):\n",
    "    return X[:, np.logical_or(col_names == 'Sex', col_names == 'Endurance')]\n",
    "\n",
    "def get_numerical_cols(X):\n",
    "    return X[:, np.logical_and(col_names != 'Sex', col_names != 'Endurance')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "pipeline_categorical = Pipeline([\n",
    "    ('selector', FunctionTransformer(get_categorical_cols, validate=False)),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "pipeline_numerical = Pipeline([\n",
    "    ('selector', FunctionTransformer(get_numerical_cols, validate=False)),\n",
    "    ('featureselector', FeatureSelector(selection='idx')),\n",
    "    ('scale', Scale(strategy='raw')),\n",
    "    ('polyfeatures', PolynomialFeatures(degree=1))\n",
    "])\n",
    "\n",
    "pipeline_preprocessing = FeatureUnion([\n",
    "    ('categorical', pipeline_categorical),\n",
    "    ('numerical', pipeline_numerical)\n",
    "])\n",
    "\n",
    "pipeline_preprocessing_with_decomposition = Pipeline([\n",
    "    ('categorical', pipeline_preprocessing),\n",
    "    ('decomposition', Decomposition(strategy='raw', N=10))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBCLASSIFIER\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:   28.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.814\n",
      "\tbest params\n",
      "{'preprocessing__categorical__numerical__featureselector__selection': 'raw',\n",
      " 'preprocessing__categorical__numerical__polyfeatures__degree': 1,\n",
      " 'preprocessing__categorical__numerical__scale__strategy': 'raw',\n",
      " 'preprocessing__decomposition__N': 7,\n",
      " 'preprocessing__decomposition__strategy': 'raw'}\n",
      "----------\n",
      "EXTRATREECLASSIFIER\n",
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 180 out of 180 | elapsed:    7.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.713\n",
      "\tbest params\n",
      "{'preprocessing__categorical__numerical__featureselector__selection': 'idx',\n",
      " 'preprocessing__categorical__numerical__polyfeatures__degree': 2,\n",
      " 'preprocessing__categorical__numerical__scale__strategy': 'raw',\n",
      " 'preprocessing__decomposition__N': 7,\n",
      " 'preprocessing__decomposition__strategy': 'raw'}\n",
      "----------\n",
      "LOGISTICREGRESSION\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   21.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.814\n",
      "\tbest params\n",
      "{'preprocessing__categorical__numerical__featureselector__selection': 'idx',\n",
      " 'preprocessing__categorical__numerical__polyfeatures__degree': 3,\n",
      " 'preprocessing__categorical__numerical__scale__strategy': 'raw',\n",
      " 'preprocessing__decomposition__N': 7,\n",
      " 'preprocessing__decomposition__strategy': 'pca'}\n",
      "----------\n",
      "GAUSSIANNB\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   15.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.791\n",
      "\tbest params\n",
      "{'preprocessing__categorical__numerical__featureselector__selection': 'idx',\n",
      " 'preprocessing__categorical__numerical__polyfeatures__degree': 3,\n",
      " 'preprocessing__categorical__numerical__scale__strategy': 'raw',\n",
      " 'preprocessing__decomposition__N': 7,\n",
      " 'preprocessing__decomposition__strategy': 'pca'}\n",
      "----------\n",
      "SVC\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   17.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.791\n",
      "\tbest params\n",
      "{'preprocessing__categorical__numerical__featureselector__selection': 'raw',\n",
      " 'preprocessing__categorical__numerical__polyfeatures__degree': 1,\n",
      " 'preprocessing__categorical__numerical__scale__strategy': 'standardscaler',\n",
      " 'preprocessing__decomposition__N': 7,\n",
      " 'preprocessing__decomposition__strategy': 'raw'}\n",
      "----------\n",
      "KNEIGHBORSCLASSIFIER\n",
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "\tbest score: 0.806\n",
      "\tbest params\n",
      "{'preprocessing__categorical__numerical__featureselector__selection': 'idx',\n",
      " 'preprocessing__categorical__numerical__polyfeatures__degree': 2,\n",
      " 'preprocessing__categorical__numerical__scale__strategy': 'raw',\n",
      " 'preprocessing__decomposition__N': 7,\n",
      " 'preprocessing__decomposition__strategy': 'raw'}\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 360 out of 360 | elapsed:   18.1s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "models = {\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'ExtraTreeClassifier': ExtraTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'SVC': SVC(), \n",
    "    'KNeighborsClassifier': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessing__categorical__numerical__featureselector__selection': ['raw', 'idx'],\n",
    "    'preprocessing__categorical__numerical__polyfeatures__degree': [1, 2, 3],\n",
    "    'preprocessing__decomposition__strategy': ['raw', 'pca'],\n",
    "    'preprocessing__decomposition__N': [7, 15, 25]\n",
    "}\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'{model_name}'.upper())\n",
    "    \n",
    "    # trees do no need scaling\n",
    "    if model_name is 'XGBClassifier' or model_name is 'ExtraTreeClassifier':\n",
    "        param_grid['preprocessing__categorical__numerical__scale__strategy'] = ['raw']\n",
    "        warnings.simplefilter('ignore')  # ignore xgboost warnings\n",
    "    else:\n",
    "        param_grid['preprocessing__categorical__numerical__scale__strategy'] = ['raw', 'standardscaler']\n",
    "        warnings.simplefilter('default')\n",
    "    \n",
    "    pipeline_full = Pipeline([\n",
    "        ('preprocessing', pipeline_preprocessing_with_decomposition),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline_full, param_grid, cv=5, scoring='accuracy',\n",
    "                                verbose=1)\n",
    "    grid_search.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    print(f'\\tbest score: {grid_search.best_score_:.3f}')\n",
    "    print('\\tbest params')\n",
    "    pprint.pprint(grid_search.best_params_)\n",
    "    \n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# featureselection selection = ['raw', 'idx']\n",
    "# polyfeature degree = [1, 2, 3]\n",
    "# decomposition strategy = ['raw', 'pca']\n",
    "# decomposition n = [1, 3, 9, 25]\n",
    "# model model = ['XGBClassifier', 'ExtraTreeClassifier', 'LogisticRegression', 'GaussianNB', 'SVC', 'KNeighborsClassifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'preprocessing__categorical__numerical__featureselector__selection': 'raw',\n",
       " 'preprocessing__categorical__numerical__polyfeatures__degree': 1,\n",
       " 'preprocessing__categorical__numerical__scale__strategy': 'raw',\n",
       " 'preprocessing__decomposition__N': 7,\n",
       " 'preprocessing__decomposition__strategy': 'raw'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('preprocessing', Pipeline(memory=None,\n",
       "     steps=[('categorical', FeatureUnion(n_jobs=1,\n",
       "       transformer_list=[('categorical', Pipeline(memory=None,\n",
       "     steps=[('selector', FunctionTransformer(accept_sparse=False,\n",
       "          func=<function get_categorical_cols at 0x7f4a026f50d0>,\n",
       "       ...owski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform'))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_full.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/romain/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    }
   ],
   "source": [
    "pipeline_full = Pipeline([\n",
    "        ('preprocessing', pipeline_preprocessing_with_decomposition),\n",
    "        ('classifier', XGBClassifier())\n",
    "    ])\n",
    "pipeline_full.fit(X_train, y_train.ravel())\n",
    "predictions = pipeline_full.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = grid_search.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test.ravel() == predictions) / y_test.shape[0] * 100"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fatigue",
   "language": "python",
   "name": "fatigue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
