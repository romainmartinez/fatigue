{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Fatigue\n",
    "- GitHub [link](https://github.com/romainmartinez/fatigue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todos\n",
    "- keras/tensorflow: [link](https://medium.com/@williamkoehrsen/deep-neural-network-classifier-32c12ff46b6c)\n",
    "- model optimization\n",
    "- drop endurance\n",
    "- viz xgboost\n",
    "- random indices\n",
    "- add sex in pipeline\n",
    "- report html\n",
    "- add roc auc in title\n",
    "- feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('.', 'data/')\n",
    "DATA_FILE = 'DatabaseRPT.mat'\n",
    "mat = sio.loadmat(os.path.join(DATA_PATH, DATA_FILE))['DataBaseRPT'][0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label\n",
    "    - `Y` (1, 162): 1 = prefatigue, 2 = fatigue\n",
    "\n",
    "- used features\n",
    "    - `AllX` (24, 162): 24 (6 DoF x 4 variables) x 162 (81 participants x 2 time points).\n",
    "    - `CAssignAll` (1, 24): AllX column assignment\n",
    "\n",
    "    - `Sex` (1, 162)\n",
    "    - `Endurance` (1, 162)\n",
    "\n",
    "- not used\n",
    "    - `BestX` (7, 162): 7 (variables with SRM>0.8) x 162 (81 participants x 2 time points) matrix. Contains data only for the most responsive variables (SRM>0.8).\n",
    "    - `CAssignBest` (1, 7): BestX column assignment.\n",
    "    - `Age` (1, 162): too much NaN.\n",
    "    - `Height` (1, 162): too much NaN.\n",
    "    - `Weight` (1, 162) Too much NaN.\n",
    "    - `SubjectKey` (1, 162): useless.\n",
    "    - `SID` (1, 162): useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [i[0] for i in mat['CAssignAll'].flatten()]\n",
    "# find variable with SRM > .8\n",
    "srm_names = np.array([i[0] for i in mat['CAssignBest'].flatten()])\n",
    "srm_idx = np.in1d(col_names, srm_names)\n",
    "\n",
    "# add `AllX`\n",
    "X = mat['AllX'].T\n",
    "\n",
    "# add `Sex`\n",
    "X = np.c_[X, mat['Sex'].T]\n",
    "col_names.append('Sex')\n",
    "\n",
    "# add `Endurance`\n",
    "X = np.c_[X, mat['Endurance'].T]\n",
    "col_names.append('Endurance')\n",
    "\n",
    "col_names = np.array(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "y = mat['Y'].T\n",
    "y = LabelBinarizer().fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(X, columns=col_names)\n",
    "df['fatigue (label)'] = y\n",
    "\n",
    "# generate pandas report\n",
    "REPORT_FILENAME = './pandas_report.html'\n",
    "if not os.path.isfile(REPORT_FILENAME):\n",
    "    import pandas_profiling\n",
    "    report = pandas_profiling.ProfileReport(df)\n",
    "    report.to_file('./pandas_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data & shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data & shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveElbFlexMean</th>\n",
       "      <th>ROMElbFlexMean</th>\n",
       "      <th>AveElbFlexSD</th>\n",
       "      <th>ROMElbFlexSD</th>\n",
       "      <th>AveShPlaneMean</th>\n",
       "      <th>ROMShPlaneMean</th>\n",
       "      <th>AveShPlaneSD</th>\n",
       "      <th>ROMShPlaneSD</th>\n",
       "      <th>AveShEleMean</th>\n",
       "      <th>ROMShEleMean</th>\n",
       "      <th>...</th>\n",
       "      <th>ROMTrYMean</th>\n",
       "      <th>AveTrYSD</th>\n",
       "      <th>ROMTrYSD</th>\n",
       "      <th>AveTrZMean</th>\n",
       "      <th>ROMTrZMean</th>\n",
       "      <th>AveTrZSD</th>\n",
       "      <th>ROMTrZSD</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Endurance</th>\n",
       "      <th>fatigue (label)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105.983144</td>\n",
       "      <td>63.339618</td>\n",
       "      <td>2.219401</td>\n",
       "      <td>1.794134</td>\n",
       "      <td>23.518597</td>\n",
       "      <td>13.624799</td>\n",
       "      <td>1.338393</td>\n",
       "      <td>2.357813</td>\n",
       "      <td>80.274017</td>\n",
       "      <td>2.942674</td>\n",
       "      <td>...</td>\n",
       "      <td>13.629558</td>\n",
       "      <td>1.112671</td>\n",
       "      <td>1.977798</td>\n",
       "      <td>-0.550047</td>\n",
       "      <td>2.671822</td>\n",
       "      <td>0.228494</td>\n",
       "      <td>0.711787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.166216</td>\n",
       "      <td>61.875226</td>\n",
       "      <td>2.239310</td>\n",
       "      <td>2.548458</td>\n",
       "      <td>22.851141</td>\n",
       "      <td>11.726534</td>\n",
       "      <td>1.182490</td>\n",
       "      <td>1.401127</td>\n",
       "      <td>77.897777</td>\n",
       "      <td>4.062635</td>\n",
       "      <td>...</td>\n",
       "      <td>15.078508</td>\n",
       "      <td>0.910697</td>\n",
       "      <td>1.003788</td>\n",
       "      <td>-0.208865</td>\n",
       "      <td>1.242553</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.496108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.914284</td>\n",
       "      <td>60.930029</td>\n",
       "      <td>1.482458</td>\n",
       "      <td>1.167593</td>\n",
       "      <td>27.289316</td>\n",
       "      <td>12.291697</td>\n",
       "      <td>1.223189</td>\n",
       "      <td>2.452705</td>\n",
       "      <td>83.932823</td>\n",
       "      <td>2.886935</td>\n",
       "      <td>...</td>\n",
       "      <td>14.311074</td>\n",
       "      <td>0.979720</td>\n",
       "      <td>2.070705</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.934767</td>\n",
       "      <td>0.488540</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.066549</td>\n",
       "      <td>59.524098</td>\n",
       "      <td>2.364182</td>\n",
       "      <td>1.849991</td>\n",
       "      <td>23.083816</td>\n",
       "      <td>7.519415</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>3.503819</td>\n",
       "      <td>78.701025</td>\n",
       "      <td>2.997990</td>\n",
       "      <td>...</td>\n",
       "      <td>16.178023</td>\n",
       "      <td>1.418294</td>\n",
       "      <td>3.521951</td>\n",
       "      <td>-0.544067</td>\n",
       "      <td>1.885480</td>\n",
       "      <td>0.610577</td>\n",
       "      <td>0.851287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.259333</td>\n",
       "      <td>81.531138</td>\n",
       "      <td>2.610755</td>\n",
       "      <td>3.632922</td>\n",
       "      <td>42.387152</td>\n",
       "      <td>27.789377</td>\n",
       "      <td>1.605530</td>\n",
       "      <td>2.027628</td>\n",
       "      <td>71.280986</td>\n",
       "      <td>8.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>8.815273</td>\n",
       "      <td>0.709582</td>\n",
       "      <td>1.250228</td>\n",
       "      <td>-0.123442</td>\n",
       "      <td>1.065910</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveElbFlexMean  ROMElbFlexMean  AveElbFlexSD  ROMElbFlexSD  AveShPlaneMean  \\\n",
       "0      105.983144       63.339618      2.219401      1.794134       23.518597   \n",
       "1      106.166216       61.875226      2.239310      2.548458       22.851141   \n",
       "2      100.914284       60.930029      1.482458      1.167593       27.289316   \n",
       "3      105.066549       59.524098      2.364182      1.849991       23.083816   \n",
       "4       93.259333       81.531138      2.610755      3.632922       42.387152   \n",
       "\n",
       "   ROMShPlaneMean  AveShPlaneSD  ROMShPlaneSD  AveShEleMean  ROMShEleMean  \\\n",
       "0       13.624799      1.338393      2.357813     80.274017      2.942674   \n",
       "1       11.726534      1.182490      1.401127     77.897777      4.062635   \n",
       "2       12.291697      1.223189      2.452705     83.932823      2.886935   \n",
       "3        7.519415      1.510000      3.503819     78.701025      2.997990   \n",
       "4       27.789377      1.605530      2.027628     71.280986      8.000008   \n",
       "\n",
       "        ...         ROMTrYMean  AveTrYSD  ROMTrYSD  AveTrZMean  ROMTrZMean  \\\n",
       "0       ...          13.629558  1.112671  1.977798   -0.550047    2.671822   \n",
       "1       ...          15.078508  0.910697  1.003788   -0.208865    1.242553   \n",
       "2       ...          14.311074  0.979720  2.070705    0.096174    0.934767   \n",
       "3       ...          16.178023  1.418294  3.521951   -0.544067    1.885480   \n",
       "4       ...           8.815273  0.709582  1.250228   -0.123442    1.065910   \n",
       "\n",
       "   AveTrZSD  ROMTrZSD  Sex  Endurance  fatigue (label)  \n",
       "0  0.228494  0.711787  2.0        2.0                0  \n",
       "1  0.541000  0.496108  2.0        2.0                1  \n",
       "2  0.488540  0.317386  2.0        8.0                0  \n",
       "3  0.610577  0.851287  2.0        8.0                1  \n",
       "4  0.415764  0.404298  2.0        4.0                0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_categorical_cols(X):\n",
    "    return X[:, np.logical_or(col_names == 'Sex', col_names == 'Endurance')]\n",
    "\n",
    "def get_numerical_cols(X):\n",
    "    return X[:, np.logical_and(col_names != 'Sex', col_names != 'Endurance')]\n",
    "\n",
    "def get_high_srm_cols(X, srm_idx=srm_idx):\n",
    "    return X[:, srm_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# categorical\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# numerical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "pipeline_categorical = Pipeline([\n",
    "    ('selector', FunctionTransformer(get_categorical_cols, validate=False)),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "pipeline_numerical = Pipeline([\n",
    "    ('selector', FunctionTransformer(get_numerical_cols, validate=False)),\n",
    "    ('selecthighsrm', FunctionTransformer(get_high_srm_cols, validate=False)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('polyfeatures', PolynomialFeatures(degree=2))\n",
    "])\n",
    "\n",
    "pipeline_preprocessing = FeatureUnion([\n",
    "    ('categorical', pipeline_categorical),\n",
    "    ('numerical', pipeline_numerical)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve, roc_curve, classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pprint\n",
    "\n",
    "class GridSearchWrapper:\n",
    "    def __init__(self, base_pipeline, model, param_grid, scoring):\n",
    "        self.base_pipeline = base_pipeline\n",
    "        self.model = model\n",
    "        self.param_grid = param_grid\n",
    "        self.scoring = scoring\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        pipeline = Pipeline([\n",
    "            ('preprocessing', self.base_pipeline),\n",
    "            ('pca', PCA(n_components=0.99, svd_solver='full')),\n",
    "            ('classifier', self.model)\n",
    "        ])\n",
    "        \n",
    "        self.grid_search = GridSearchCV(pipeline, self.param_grid, scoring=self.scoring,\n",
    "                                   cv=5, n_jobs=-1, verbose=1)\n",
    "        self.grid_search.fit(X, y)\n",
    "    \n",
    "    def print_scores(self):\n",
    "        print(f'best score ({self.scoring}): {self.grid_search.best_score_:.3f}')\n",
    "        print('\\nbest params:')\n",
    "        pprint.pprint(self.grid_search.best_params_)\n",
    "        \n",
    "    def evaluate(self, X, y):\n",
    "        y_scores = self.grid_search.predict(X)\n",
    "        report = classification_report(y, y_scores)\n",
    "        print(report)\n",
    "        \n",
    "        self.confusion_matrix(X, y)\n",
    "        self.precision_recall_vs_threshold(X, y)\n",
    "        self.roc_curve(X, y)\n",
    "        \n",
    "    def confusion_matrix(self, X, y, percentage=True):   \n",
    "        y_pred = self.grid_search.best_estimator_.predict(X)\n",
    "        cm = confusion_matrix(y, y_pred)\n",
    "        if percentage:\n",
    "            cm = cm / cm.sum(axis=1)[:, np.newaxis] * 100\n",
    "            \n",
    "        plt.figure(figsize=(8, 4))\n",
    "        sns.heatmap(cm, annot=True, cmap='RdYlGn')\n",
    "        plt.title('Confusion matrix')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.ylabel('True')\n",
    "        \n",
    "    def precision_recall_vs_threshold(self, X, y):\n",
    "        y_scores = self.grid_search.predict_proba(X)[:, 1]\n",
    "        precision, recall, thresholds = precision_recall_curve(y, y_scores)\n",
    "        plt.figure(figsize=(8, 8))\n",
    "        plt.title(\"Precision and Recall Scores as a function of the decision threshold\")\n",
    "        plt.plot(thresholds, precision[:-1], \"b--\", label=\"Precision\")\n",
    "        plt.plot(thresholds, recall[:-1], \"g-\", label=\"Recall\")\n",
    "        plt.ylabel(\"Score\")\n",
    "        plt.xlabel(\"Decision Threshold\")\n",
    "        plt.legend(loc='best')\n",
    "        \n",
    "    \n",
    "    def roc_curve(self, X, y):\n",
    "        y_scores = self.grid_search.predict_proba(X)[:, 1]\n",
    "        fpr, tpr, auc_thresholds = roc_curve(y, y_scores)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.title('ROC Curve')\n",
    "        plt.plot(fpr, tpr, linewidth=2)\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.axis([-0.005, 1, 0, 1.005])\n",
    "        plt.xticks(np.arange(0,1, 0.05), rotation=90)\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate (Recall)\")\n",
    "        \n",
    "    def decision_threshold(self, X, y, t=0.5):\n",
    "        y_scores = self.grid_search.predict_proba(X)[:, 1]\n",
    "        y_scores_adj = [1 if y >= t else 0 for y in y_scores]\n",
    "\n",
    "        cm = confusion_matrix(y, y_scores_adj)\n",
    "        sns.heatmap(cm, annot=True)\n",
    "        plt.show()\n",
    "\n",
    "        precision, recall, thresholds = precision_recall_curve(y, y_scores)\n",
    "        plt.figure(figsize=(8,8))\n",
    "        plt.title(\"Precision and Recall curve (^=current threshold)\")\n",
    "        plt.step(recall, precision, color='b', alpha=0.2,\n",
    "                 where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.2,\n",
    "                         color='b')\n",
    "        plt.ylim([0.5, 1.01]);\n",
    "        plt.xlim([0.5, 1.01]);\n",
    "        plt.xlabel('Recall');\n",
    "        plt.ylabel('Precision');\n",
    "\n",
    "        # plot the current threshold on the line\n",
    "        close_default_clf = np.argmin(np.abs(thresholds - t))\n",
    "        plt.plot(recall[close_default_clf], precision[close_default_clf], '^', c='k',\n",
    "                markersize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### metrics wrap up\n",
    "#### Precision\n",
    "$\\frac{TP}{\\text{n}^o \\text{predicted positives}} = \\frac{TP}{TP + FP}$\n",
    "\n",
    "- high precision = less _false positive_\n",
    "- _example_: getting $0.8$ precision means that when it claims to detect a label, it is right $80$% of the time\n",
    "\n",
    "#### Recall\n",
    "$\\frac{TP}{\\text{n}^o \\text{actual positives}} = \\frac{TP}{TP + FN}$\n",
    "\n",
    "- high recall = less _false negative_\n",
    "- _example_: getting $0.8$ recall means that it detect $80$% of the label\n",
    "\n",
    "#### in our case\n",
    "We want to detect when a participant has fatigue $\\rightarrow$ reduce **false negative** $\\rightarrow$ optimize for __recall__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'preprocessing__numerical__selecthighsrm': [None, FunctionTransformer(get_high_srm_cols, validate=False)],\n",
    "    'preprocessing__numerical__polyfeatures': [None, PolynomialFeatures(degree=1), PolynomialFeatures(degree=2), PolynomialFeatures(degree=3)],\n",
    "    'preprocessing__numerical__scale': [None, StandardScaler()],\n",
    "    'pca': [None, PCA(n_components=0.99, svd_solver='full')]\n",
    "}\n",
    "\n",
    "scoring = 'roc_auc'\n",
    "\n",
    "# param_grid = {\n",
    "#     'preprocessing__numerical__selecthighsrm': [FunctionTransformer(get_high_srm_cols, validate=False)],\n",
    "#     'preprocessing__numerical__polyfeatures': [PolynomialFeatures(degree=1)],\n",
    "#     'preprocessing__numerical__scale': [None],\n",
    "#     'pca': [None]\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    4.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "wrapper = GridSearchWrapper(base_pipeline=pipeline_preprocessing,\n",
    "                            model=RandomForestClassifier(random_state=RANDOM_SEED),\n",
    "                            param_grid=param_grid,\n",
    "                            scoring=scoring)\n",
    "\n",
    "wrapper.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score (roc_auc): 0.851\n",
      "\n",
      "best params:\n",
      "{'pca': PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
      "  svd_solver='full', tol=0.0, whiten=False),\n",
      " 'preprocessing__numerical__polyfeatures': None,\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7fc9dae0a378>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n"
     ]
    }
   ],
   "source": [
    "wrapper.print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    4.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "wrapper = GridSearchWrapper(base_pipeline=pipeline_preprocessing,\n",
    "                            model=LogisticRegression(random_state=RANDOM_SEED),\n",
    "                            param_grid=param_grid,\n",
    "                            scoring=scoring)\n",
    "\n",
    "wrapper.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score (recall): 0.847\n",
      "\n",
      "best params:\n",
      "{'pca': PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
      "  svd_solver='full', tol=0.0, whiten=False),\n",
      " 'preprocessing__numerical__polyfeatures': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False),\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f4e70ae7ea0>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n"
     ]
    }
   ],
   "source": [
    "wrapper.print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "wrapper = GridSearchWrapper(base_pipeline=pipeline_preprocessing,\n",
    "                            model=GaussianNB(),\n",
    "                            param_grid=param_grid,\n",
    "                            scoring=scoring)\n",
    "\n",
    "wrapper.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score (recall): 0.908\n",
      "\n",
      "best params:\n",
      "{'pca': None,\n",
      " 'preprocessing__numerical__polyfeatures': None,\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f4e70ae7ea0>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n"
     ]
    }
   ],
   "source": [
    "wrapper.print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-nearest neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    3.2s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "wrapper = GridSearchWrapper(base_pipeline=pipeline_preprocessing,\n",
    "                            model=KNeighborsClassifier(),\n",
    "                            param_grid=param_grid,\n",
    "                            scoring=scoring)\n",
    "\n",
    "wrapper.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score (recall): 0.800\n",
      "\n",
      "best params:\n",
      "{'pca': None,\n",
      " 'preprocessing__numerical__polyfeatures': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False),\n",
      " 'preprocessing__numerical__scale': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f4e70ae7ea0>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n"
     ]
    }
   ],
   "source": [
    "wrapper.print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://jessesw.com/XG-Boost/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pca': [None,\n",
       "  PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
       "    svd_solver='full', tol=0.0, whiten=False)],\n",
       " 'preprocessing__numerical__polyfeatures': [None,\n",
       "  PolynomialFeatures(degree=1, include_bias=True, interaction_only=False),\n",
       "  PolynomialFeatures(degree=2, include_bias=True, interaction_only=False),\n",
       "  PolynomialFeatures(degree=3, include_bias=True, interaction_only=False)],\n",
       " 'preprocessing__numerical__scale': [None,\n",
       "  StandardScaler(copy=True, with_mean=True, with_std=True)],\n",
       " 'preprocessing__numerical__selecthighsrm': [None,\n",
       "  FunctionTransformer(accept_sparse=False,\n",
       "            func=<function get_high_srm_cols at 0x7f4e70ae7ea0>,\n",
       "            inv_kw_args=None, inverse_func=None, kw_args=None,\n",
       "            pass_y='deprecated', validate=False)]}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 160 out of 160 | elapsed:    7.6s finished\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore')\n",
    "wrapper = GridSearchWrapper(base_pipeline=pipeline_preprocessing,\n",
    "                            model=XGBClassifier(random_state=RANDOM_SEED),\n",
    "                            param_grid=param_grid,\n",
    "                            scoring=scoring)\n",
    "\n",
    "wrapper.fit(X_train, y_train.ravel())\n",
    "warnings.simplefilter('default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best score (recall): 0.831\n",
      "\n",
      "best params:\n",
      "{'pca': None,\n",
      " 'preprocessing__numerical__polyfeatures': None,\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': None}\n"
     ]
    }
   ],
   "source": [
    "wrapper.print_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=26, activation='relu'))\n",
    "    model.add(Dense(26, activation='relu'))\n",
    "    model.add(Dense(26, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "NN = KerasClassifier(build_fn=create_model,\n",
    "                     epochs=10,\n",
    "                     batch_size=10,\n",
    "                     verbose=1)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = cross_val_score(NN, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fatigue",
   "language": "python",
   "name": "fatigue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
