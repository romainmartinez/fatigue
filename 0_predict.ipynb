{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Fatigue\n",
    "- GitHub [link](https://github.com/romainmartinez/fatigue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todos\n",
    "- onehot encoding\n",
    "- feature importance in pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('.', 'data/')\n",
    "DATA_FILE = 'DatabaseRPT.mat'\n",
    "mat = sio.loadmat(os.path.join(DATA_PATH, DATA_FILE))['DataBaseRPT'][0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label\n",
    "    - `Y` (1, 162): 1 = prefatigue, 2 = fatigue\n",
    "\n",
    "- used features\n",
    "    - `AllX` (24, 162): 24 (6 DoF x 4 variables) x 162 (81 participants x 2 time points).\n",
    "    - `CAssignAll` (1, 24): AllX column assignment\n",
    "\n",
    "    - `Sex` (1, 162)\n",
    "    - `Endurance` (1, 162)\n",
    "\n",
    "- not used\n",
    "    - `BestX` (7, 162): 7 (variables with SRM>0.8) x 162 (81 participants x 2 time points) matrix. Contains data only for the most responsive variables (SRM>0.8).\n",
    "    - `CAssignBest` (1, 7): BestX column assignment.\n",
    "    - `Age` (1, 162): too much NaN.\n",
    "    - `Height` (1, 162): too much NaN.\n",
    "    - `Weight` (1, 162) Too much NaN.\n",
    "    - `SubjectKey` (1, 162): useless.\n",
    "    - `SID` (1, 162): useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [i[0] for i in mat['CAssignAll'].flatten()]\n",
    "\n",
    "# add `AllX`\n",
    "X = mat['AllX'].T\n",
    "\n",
    "# add `Sex`\n",
    "X = np.c_[X, mat['Sex'].T]\n",
    "col_names.append('Sex')\n",
    "\n",
    "# add `Endurance`\n",
    "X = np.c_[X, mat['Endurance'].T]\n",
    "col_names.append('Endurance')\n",
    "\n",
    "col_names = np.array(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mat['Y'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data & shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data & shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveElbFlexMean</th>\n",
       "      <th>ROMElbFlexMean</th>\n",
       "      <th>AveElbFlexSD</th>\n",
       "      <th>ROMElbFlexSD</th>\n",
       "      <th>AveShPlaneMean</th>\n",
       "      <th>ROMShPlaneMean</th>\n",
       "      <th>AveShPlaneSD</th>\n",
       "      <th>ROMShPlaneSD</th>\n",
       "      <th>AveShEleMean</th>\n",
       "      <th>ROMShEleMean</th>\n",
       "      <th>...</th>\n",
       "      <th>AveTrYMean</th>\n",
       "      <th>ROMTrYMean</th>\n",
       "      <th>AveTrYSD</th>\n",
       "      <th>ROMTrYSD</th>\n",
       "      <th>AveTrZMean</th>\n",
       "      <th>ROMTrZMean</th>\n",
       "      <th>AveTrZSD</th>\n",
       "      <th>ROMTrZSD</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Endurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105.983144</td>\n",
       "      <td>63.339618</td>\n",
       "      <td>2.219401</td>\n",
       "      <td>1.794134</td>\n",
       "      <td>23.518597</td>\n",
       "      <td>13.624799</td>\n",
       "      <td>1.338393</td>\n",
       "      <td>2.357813</td>\n",
       "      <td>80.274017</td>\n",
       "      <td>2.942674</td>\n",
       "      <td>...</td>\n",
       "      <td>16.382423</td>\n",
       "      <td>13.629558</td>\n",
       "      <td>1.112671</td>\n",
       "      <td>1.977798</td>\n",
       "      <td>-0.550047</td>\n",
       "      <td>2.671822</td>\n",
       "      <td>0.228494</td>\n",
       "      <td>0.711787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.166216</td>\n",
       "      <td>61.875226</td>\n",
       "      <td>2.239310</td>\n",
       "      <td>2.548458</td>\n",
       "      <td>22.851141</td>\n",
       "      <td>11.726534</td>\n",
       "      <td>1.182490</td>\n",
       "      <td>1.401127</td>\n",
       "      <td>77.897777</td>\n",
       "      <td>4.062635</td>\n",
       "      <td>...</td>\n",
       "      <td>16.041630</td>\n",
       "      <td>15.078508</td>\n",
       "      <td>0.910697</td>\n",
       "      <td>1.003788</td>\n",
       "      <td>-0.208865</td>\n",
       "      <td>1.242553</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.496108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.914284</td>\n",
       "      <td>60.930029</td>\n",
       "      <td>1.482458</td>\n",
       "      <td>1.167593</td>\n",
       "      <td>27.289316</td>\n",
       "      <td>12.291697</td>\n",
       "      <td>1.223189</td>\n",
       "      <td>2.452705</td>\n",
       "      <td>83.932823</td>\n",
       "      <td>2.886935</td>\n",
       "      <td>...</td>\n",
       "      <td>15.039772</td>\n",
       "      <td>14.311074</td>\n",
       "      <td>0.979720</td>\n",
       "      <td>2.070705</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.934767</td>\n",
       "      <td>0.488540</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.066549</td>\n",
       "      <td>59.524098</td>\n",
       "      <td>2.364182</td>\n",
       "      <td>1.849991</td>\n",
       "      <td>23.083816</td>\n",
       "      <td>7.519415</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>3.503819</td>\n",
       "      <td>78.701025</td>\n",
       "      <td>2.997990</td>\n",
       "      <td>...</td>\n",
       "      <td>16.070120</td>\n",
       "      <td>16.178023</td>\n",
       "      <td>1.418294</td>\n",
       "      <td>3.521951</td>\n",
       "      <td>-0.544067</td>\n",
       "      <td>1.885480</td>\n",
       "      <td>0.610577</td>\n",
       "      <td>0.851287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.259333</td>\n",
       "      <td>81.531138</td>\n",
       "      <td>2.610755</td>\n",
       "      <td>3.632922</td>\n",
       "      <td>42.387152</td>\n",
       "      <td>27.789377</td>\n",
       "      <td>1.605530</td>\n",
       "      <td>2.027628</td>\n",
       "      <td>71.280986</td>\n",
       "      <td>8.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>8.908385</td>\n",
       "      <td>8.815273</td>\n",
       "      <td>0.709582</td>\n",
       "      <td>1.250228</td>\n",
       "      <td>-0.123442</td>\n",
       "      <td>1.065910</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveElbFlexMean  ROMElbFlexMean  AveElbFlexSD  ROMElbFlexSD  AveShPlaneMean  \\\n",
       "0      105.983144       63.339618      2.219401      1.794134       23.518597   \n",
       "1      106.166216       61.875226      2.239310      2.548458       22.851141   \n",
       "2      100.914284       60.930029      1.482458      1.167593       27.289316   \n",
       "3      105.066549       59.524098      2.364182      1.849991       23.083816   \n",
       "4       93.259333       81.531138      2.610755      3.632922       42.387152   \n",
       "\n",
       "   ROMShPlaneMean  AveShPlaneSD  ROMShPlaneSD  AveShEleMean  ROMShEleMean  \\\n",
       "0       13.624799      1.338393      2.357813     80.274017      2.942674   \n",
       "1       11.726534      1.182490      1.401127     77.897777      4.062635   \n",
       "2       12.291697      1.223189      2.452705     83.932823      2.886935   \n",
       "3        7.519415      1.510000      3.503819     78.701025      2.997990   \n",
       "4       27.789377      1.605530      2.027628     71.280986      8.000008   \n",
       "\n",
       "     ...      AveTrYMean  ROMTrYMean  AveTrYSD  ROMTrYSD  AveTrZMean  \\\n",
       "0    ...       16.382423   13.629558  1.112671  1.977798   -0.550047   \n",
       "1    ...       16.041630   15.078508  0.910697  1.003788   -0.208865   \n",
       "2    ...       15.039772   14.311074  0.979720  2.070705    0.096174   \n",
       "3    ...       16.070120   16.178023  1.418294  3.521951   -0.544067   \n",
       "4    ...        8.908385    8.815273  0.709582  1.250228   -0.123442   \n",
       "\n",
       "   ROMTrZMean  AveTrZSD  ROMTrZSD  Sex  Endurance  \n",
       "0    2.671822  0.228494  0.711787  2.0        2.0  \n",
       "1    1.242553  0.541000  0.496108  2.0        2.0  \n",
       "2    0.934767  0.488540  0.317386  2.0        8.0  \n",
       "3    1.885480  0.610577  0.851287  2.0        8.0  \n",
       "4    1.065910  0.415764  0.404298  2.0        4.0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(X, columns=col_names).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- one-hot encoding: done\n",
    "- scaler: done\n",
    "- feature selection (ANOVA, model based, etc.)\n",
    "- PolynomialFeatures\n",
    "- different models (XGBoost, scikit, keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom class\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline, make_union\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "# Scale\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.preprocessing.data import QuantileTransformer\n",
    "\n",
    "# feature selection\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# models\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# other\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "class Scale(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy='Raw'):\n",
    "        self.strategy = strategy.lower()\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_copy = X.copy()\n",
    "        if self.strategy == 'raw':\n",
    "            scaler = None\n",
    "        elif self.strategy == 'minmaxscaler':\n",
    "            scaler = MinMaxScaler()\n",
    "        elif self.strategy == 'maxabsscaler':\n",
    "            scaler = MaxAbsScaler()\n",
    "        elif self.strategy == 'standardscaler':\n",
    "            scaler = StandardScaler()\n",
    "        elif self.strategy == 'robustscaler':\n",
    "            scaler = RobustScaler(quantile_range=(25, 75))\n",
    "        elif self.strategy == 'normalizer':\n",
    "            scaler = Normalizer()\n",
    "        elif self.strategy == 'quantiletransformer':\n",
    "            scaler = QuantileTransformer(output_distribution='normal')\n",
    "        \n",
    "        if scaler is None:\n",
    "            output = X_copy\n",
    "        else:\n",
    "            output = scaler.fit_transform(X_copy)\n",
    "        return output\n",
    "\n",
    "class Decomposition(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, strategy):\n",
    "        self.strategy = strategy.lower()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return\n",
    "    \n",
    "    def transform(self, X):\n",
    "        if self.strategy == 'raw':\n",
    "            pass\n",
    "        elif self.strategy == 'pca':\n",
    "            pass\n",
    "        elif self.strategy == 'nmf':\n",
    "            pass\n",
    "        elif self.strategy == 'selectkbest':\n",
    "            pass\n",
    "        return\n",
    "    \n",
    "def get_categorical_cols(X):\n",
    "    return X[:, np.logical_or(col_names == 'Sex', col_names == 'Endurance')]\n",
    "\n",
    "def get_numerical_cols(X):\n",
    "    return X[:, np.logical_and(col_names != 'Sex', col_names != 'Endurance')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-52-955a81e62539>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-52-955a81e62539>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    http://scikit-learn.org/stable/auto_examples/plot_compare_reduction.html#sphx-glr-auto-examples-plot-compare-reduction-py\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "http://scikit-learn.org/stable/auto_examples/plot_compare_reduction.html#sphx-glr-auto-examples-plot-compare-reduction-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_categorial = make_pipeline(\n",
    "    FunctionTransformer(get_categorical_cols, validate=False),\n",
    "    OneHotEncoder(sparse=False)\n",
    ")\n",
    "\n",
    "pipeline_numerical = make_pipeline(\n",
    "    FunctionTransformer(get_numerical_cols, validate=False),\n",
    "    Scale(strategy='Raw'),\n",
    "    PolynomialFeatures(degree=1)\n",
    ")\n",
    "\n",
    "full_pipeline = make_union(\n",
    "    pipeline_categorial,\n",
    "    pipeline_numerical,\n",
    "    FeatureSelection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 25)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_numerical.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 21)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_categorial.fit_transform(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'y'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-002bc633a99c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    712\u001b[0m         transformers = Parallel(n_jobs=self.n_jobs)(\n\u001b[1;32m    713\u001b[0m             \u001b[0mdelayed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_fit_one_transformer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             for _, trans, _ in self._iter())\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_transformer_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/fatigue-WgHAVgza/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_one_transformer\u001b[0;34m(transformer, X, y)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fit_one_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'y'"
     ]
    }
   ],
   "source": [
    "full_pipeline.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fatigue",
   "language": "python",
   "name": "fatigue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
