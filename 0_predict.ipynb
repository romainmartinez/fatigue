{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Fatigue\n",
    "- GitHub [link](https://github.com/romainmartinez/fatigue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## todos\n",
    "- keras/tensorflow: [link](https://medium.com/@williamkoehrsen/deep-neural-network-classifier-32c12ff46b6c)\n",
    "- model optimization\n",
    "- apply: [link](https://towardsdatascience.com/fine-tuning-a-classifier-in-scikit-learn-66e048c21e65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Figures\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.rcParams['axes.labelsize'] = 14\n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12\n",
    "sns.set_context(\"notebook\", font_scale=1.1)\n",
    "sns.set_style(\"ticks\")\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('.', 'data/')\n",
    "DATA_FILE = 'DatabaseRPT.mat'\n",
    "mat = sio.loadmat(os.path.join(DATA_PATH, DATA_FILE))['DataBaseRPT'][0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- label\n",
    "    - `Y` (1, 162): 1 = prefatigue, 2 = fatigue\n",
    "\n",
    "- used features\n",
    "    - `AllX` (24, 162): 24 (6 DoF x 4 variables) x 162 (81 participants x 2 time points).\n",
    "    - `CAssignAll` (1, 24): AllX column assignment\n",
    "\n",
    "    - `Sex` (1, 162)\n",
    "    - `Endurance` (1, 162)\n",
    "\n",
    "- not used\n",
    "    - `BestX` (7, 162): 7 (variables with SRM>0.8) x 162 (81 participants x 2 time points) matrix. Contains data only for the most responsive variables (SRM>0.8).\n",
    "    - `CAssignBest` (1, 7): BestX column assignment.\n",
    "    - `Age` (1, 162): too much NaN.\n",
    "    - `Height` (1, 162): too much NaN.\n",
    "    - `Weight` (1, 162) Too much NaN.\n",
    "    - `SubjectKey` (1, 162): useless.\n",
    "    - `SID` (1, 162): useless."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create feature matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = [i[0] for i in mat['CAssignAll'].flatten()]\n",
    "# find variable with SRM > .8\n",
    "srm_names = np.array([i[0] for i in mat['CAssignBest'].flatten()])\n",
    "srm_idx = np.in1d(col_names, srm_names)\n",
    "\n",
    "# add `AllX`\n",
    "X = mat['AllX'].T\n",
    "\n",
    "# add `Sex`\n",
    "X = np.c_[X, mat['Sex'].T]\n",
    "col_names.append('Sex')\n",
    "\n",
    "# add `Endurance`\n",
    "X = np.c_[X, mat['Endurance'].T]\n",
    "col_names.append('Endurance')\n",
    "\n",
    "col_names = np.array(col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create label vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mat['Y'].T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pandas as pd\n",
    "\n",
    "# create dataframe\n",
    "df = pd.DataFrame(X, columns=col_names)\n",
    "df['fatigue (label)'] = y\n",
    "\n",
    "# generate pandas report\n",
    "REPORT_FILENAME = './pandas_report.html'\n",
    "if not os.path.isfile(REPORT_FILENAME):\n",
    "    import pandas_profiling\n",
    "    report = pandas_profiling.ProfileReport(df)\n",
    "    report.to_file('./pandas_report.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data & shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data & shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveElbFlexMean</th>\n",
       "      <th>ROMElbFlexMean</th>\n",
       "      <th>AveElbFlexSD</th>\n",
       "      <th>ROMElbFlexSD</th>\n",
       "      <th>AveShPlaneMean</th>\n",
       "      <th>ROMShPlaneMean</th>\n",
       "      <th>AveShPlaneSD</th>\n",
       "      <th>ROMShPlaneSD</th>\n",
       "      <th>AveShEleMean</th>\n",
       "      <th>ROMShEleMean</th>\n",
       "      <th>...</th>\n",
       "      <th>ROMTrYMean</th>\n",
       "      <th>AveTrYSD</th>\n",
       "      <th>ROMTrYSD</th>\n",
       "      <th>AveTrZMean</th>\n",
       "      <th>ROMTrZMean</th>\n",
       "      <th>AveTrZSD</th>\n",
       "      <th>ROMTrZSD</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Endurance</th>\n",
       "      <th>fatigue (label)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>105.983144</td>\n",
       "      <td>63.339618</td>\n",
       "      <td>2.219401</td>\n",
       "      <td>1.794134</td>\n",
       "      <td>23.518597</td>\n",
       "      <td>13.624799</td>\n",
       "      <td>1.338393</td>\n",
       "      <td>2.357813</td>\n",
       "      <td>80.274017</td>\n",
       "      <td>2.942674</td>\n",
       "      <td>...</td>\n",
       "      <td>13.629558</td>\n",
       "      <td>1.112671</td>\n",
       "      <td>1.977798</td>\n",
       "      <td>-0.550047</td>\n",
       "      <td>2.671822</td>\n",
       "      <td>0.228494</td>\n",
       "      <td>0.711787</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.166216</td>\n",
       "      <td>61.875226</td>\n",
       "      <td>2.239310</td>\n",
       "      <td>2.548458</td>\n",
       "      <td>22.851141</td>\n",
       "      <td>11.726534</td>\n",
       "      <td>1.182490</td>\n",
       "      <td>1.401127</td>\n",
       "      <td>77.897777</td>\n",
       "      <td>4.062635</td>\n",
       "      <td>...</td>\n",
       "      <td>15.078508</td>\n",
       "      <td>0.910697</td>\n",
       "      <td>1.003788</td>\n",
       "      <td>-0.208865</td>\n",
       "      <td>1.242553</td>\n",
       "      <td>0.541000</td>\n",
       "      <td>0.496108</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100.914284</td>\n",
       "      <td>60.930029</td>\n",
       "      <td>1.482458</td>\n",
       "      <td>1.167593</td>\n",
       "      <td>27.289316</td>\n",
       "      <td>12.291697</td>\n",
       "      <td>1.223189</td>\n",
       "      <td>2.452705</td>\n",
       "      <td>83.932823</td>\n",
       "      <td>2.886935</td>\n",
       "      <td>...</td>\n",
       "      <td>14.311074</td>\n",
       "      <td>0.979720</td>\n",
       "      <td>2.070705</td>\n",
       "      <td>0.096174</td>\n",
       "      <td>0.934767</td>\n",
       "      <td>0.488540</td>\n",
       "      <td>0.317386</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>105.066549</td>\n",
       "      <td>59.524098</td>\n",
       "      <td>2.364182</td>\n",
       "      <td>1.849991</td>\n",
       "      <td>23.083816</td>\n",
       "      <td>7.519415</td>\n",
       "      <td>1.510000</td>\n",
       "      <td>3.503819</td>\n",
       "      <td>78.701025</td>\n",
       "      <td>2.997990</td>\n",
       "      <td>...</td>\n",
       "      <td>16.178023</td>\n",
       "      <td>1.418294</td>\n",
       "      <td>3.521951</td>\n",
       "      <td>-0.544067</td>\n",
       "      <td>1.885480</td>\n",
       "      <td>0.610577</td>\n",
       "      <td>0.851287</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.259333</td>\n",
       "      <td>81.531138</td>\n",
       "      <td>2.610755</td>\n",
       "      <td>3.632922</td>\n",
       "      <td>42.387152</td>\n",
       "      <td>27.789377</td>\n",
       "      <td>1.605530</td>\n",
       "      <td>2.027628</td>\n",
       "      <td>71.280986</td>\n",
       "      <td>8.000008</td>\n",
       "      <td>...</td>\n",
       "      <td>8.815273</td>\n",
       "      <td>0.709582</td>\n",
       "      <td>1.250228</td>\n",
       "      <td>-0.123442</td>\n",
       "      <td>1.065910</td>\n",
       "      <td>0.415764</td>\n",
       "      <td>0.404298</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveElbFlexMean  ROMElbFlexMean  AveElbFlexSD  ROMElbFlexSD  AveShPlaneMean  \\\n",
       "0      105.983144       63.339618      2.219401      1.794134       23.518597   \n",
       "1      106.166216       61.875226      2.239310      2.548458       22.851141   \n",
       "2      100.914284       60.930029      1.482458      1.167593       27.289316   \n",
       "3      105.066549       59.524098      2.364182      1.849991       23.083816   \n",
       "4       93.259333       81.531138      2.610755      3.632922       42.387152   \n",
       "\n",
       "   ROMShPlaneMean  AveShPlaneSD  ROMShPlaneSD  AveShEleMean  ROMShEleMean  \\\n",
       "0       13.624799      1.338393      2.357813     80.274017      2.942674   \n",
       "1       11.726534      1.182490      1.401127     77.897777      4.062635   \n",
       "2       12.291697      1.223189      2.452705     83.932823      2.886935   \n",
       "3        7.519415      1.510000      3.503819     78.701025      2.997990   \n",
       "4       27.789377      1.605530      2.027628     71.280986      8.000008   \n",
       "\n",
       "        ...         ROMTrYMean  AveTrYSD  ROMTrYSD  AveTrZMean  ROMTrZMean  \\\n",
       "0       ...          13.629558  1.112671  1.977798   -0.550047    2.671822   \n",
       "1       ...          15.078508  0.910697  1.003788   -0.208865    1.242553   \n",
       "2       ...          14.311074  0.979720  2.070705    0.096174    0.934767   \n",
       "3       ...          16.178023  1.418294  3.521951   -0.544067    1.885480   \n",
       "4       ...           8.815273  0.709582  1.250228   -0.123442    1.065910   \n",
       "\n",
       "   AveTrZSD  ROMTrZSD  Sex  Endurance  fatigue (label)  \n",
       "0  0.228494  0.711787  2.0        2.0                1  \n",
       "1  0.541000  0.496108  2.0        2.0                2  \n",
       "2  0.488540  0.317386  2.0        8.0                1  \n",
       "3  0.610577  0.851287  2.0        8.0                2  \n",
       "4  0.415764  0.404298  2.0        4.0                1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom class\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "# decomposition\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.decomposition import PCA, NMF\n",
    "\n",
    "# scale\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# models\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import ExtraTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# other\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "def get_categorical_cols(X):\n",
    "    return X[:, np.logical_or(col_names == 'Sex', col_names == 'Endurance')]\n",
    "\n",
    "def get_numerical_cols(X):\n",
    "    return X[:, np.logical_and(col_names != 'Sex', col_names != 'Endurance')]\n",
    "\n",
    "def get_high_srm_cols(X, srm_idx=srm_idx):\n",
    "    return X[:, srm_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "pipeline_categorical = Pipeline([\n",
    "    ('selector', FunctionTransformer(get_categorical_cols, validate=False)),\n",
    "    ('encoder', OneHotEncoder(sparse=False))\n",
    "])\n",
    "\n",
    "pipeline_numerical = Pipeline([\n",
    "    ('selector', FunctionTransformer(get_numerical_cols, validate=False)),\n",
    "    ('selecthighsrm', FunctionTransformer(get_high_srm_cols, validate=False)),\n",
    "    ('scale', StandardScaler()),\n",
    "    ('polyfeatures', PolynomialFeatures(degree=2))\n",
    "])\n",
    "\n",
    "pipeline_preprocessing = FeatureUnion([\n",
    "    ('categorical', pipeline_categorical),\n",
    "    ('numerical', pipeline_numerical)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBCLASSIFIER\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:   19.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.822\n",
      "\tbest params\n",
      "{'pca': PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
      "  svd_solver='full', tol=0.0, whiten=False),\n",
      " 'preprocessing__numerical__polyfeatures': None,\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f0afb3ab510>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n",
      "accuracy = 72.72727272727273\n",
      "----------\n",
      "EXTRATREECLASSIFIER\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.752\n",
      "\tbest params\n",
      "{'pca': None,\n",
      " 'preprocessing__numerical__polyfeatures': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False),\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f0afb3ab510>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n",
      "accuracy = 60.60606060606061\n",
      "----------\n",
      "LOGISTICREGRESSION\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    7.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.845\n",
      "\tbest params\n",
      "{'pca': PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
      "  svd_solver='full', tol=0.0, whiten=False),\n",
      " 'preprocessing__numerical__polyfeatures': PolynomialFeatures(degree=3, include_bias=True, interaction_only=False),\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f0afb3ab510>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n",
      "accuracy = 69.6969696969697\n",
      "----------\n",
      "GAUSSIANNB\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.845\n",
      "\tbest params\n",
      "{'pca': PCA(copy=True, iterated_power='auto', n_components=0.99, random_state=None,\n",
      "  svd_solver='full', tol=0.0, whiten=False),\n",
      " 'preprocessing__numerical__polyfeatures': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False),\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f0afb3ab510>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n",
      "accuracy = 75.75757575757575\n",
      "----------\n",
      "SVC\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    5.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tbest score: 0.791\n",
      "\tbest params\n",
      "{'pca': None,\n",
      " 'preprocessing__numerical__polyfeatures': None,\n",
      " 'preprocessing__numerical__scale': StandardScaler(copy=True, with_mean=True, with_std=True),\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f0afb3ab510>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n",
      "accuracy = 75.75757575757575\n",
      "----------\n",
      "KNEIGHBORSCLASSIFIER\n",
      "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
      "\tbest score: 0.806\n",
      "\tbest params\n",
      "{'pca': None,\n",
      " 'preprocessing__numerical__polyfeatures': PolynomialFeatures(degree=2, include_bias=True, interaction_only=False),\n",
      " 'preprocessing__numerical__scale': None,\n",
      " 'preprocessing__numerical__selecthighsrm': FunctionTransformer(accept_sparse=False,\n",
      "          func=<function get_high_srm_cols at 0x7f0afb3ab510>,\n",
      "          inv_kw_args=None, inverse_func=None, kw_args=None,\n",
      "          pass_y='deprecated', validate=False)}\n",
      "accuracy = 66.66666666666666\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done 160 out of 160 | elapsed:    5.6s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pprint\n",
    "import warnings\n",
    "\n",
    "models = {\n",
    "    'XGBClassifier': XGBClassifier(),\n",
    "    'ExtraTreeClassifier': ExtraTreeClassifier(),\n",
    "    'LogisticRegression': LogisticRegression(),\n",
    "    'GaussianNB': GaussianNB(),\n",
    "    'SVC': SVC(), \n",
    "    'KNeighborsClassifier': KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'preprocessing__numerical__selecthighsrm': [None, FunctionTransformer(get_high_srm_cols, validate=False)],\n",
    "    'preprocessing__numerical__polyfeatures': [None, PolynomialFeatures(degree=1), PolynomialFeatures(degree=2), PolynomialFeatures(degree=3)],\n",
    "    'preprocessing__numerical__scale': [None, StandardScaler()],\n",
    "    'pca': [None, PCA(n_components=0.99, svd_solver='full')]\n",
    "}\n",
    "\n",
    "scoring = ['accuracy', 'precision', 'recall', 'f1']\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(f'{model_name}'.upper())\n",
    "    \n",
    "    # ignore xgboost warnings\n",
    "    if model_name is 'XGBClassifier':\n",
    "         warnings.simplefilter('ignore')\n",
    "    else:\n",
    "        warnings.simplefilter('default')\n",
    "    \n",
    "    pipeline_full = Pipeline([\n",
    "        ('preprocessing', pipeline_preprocessing),\n",
    "        ('pca', PCA(n_components=0.99, svd_solver='full')),\n",
    "        ('classifier', model)\n",
    "    ])\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline_full, param_grid, cv=5, scoring='accuracy',\n",
    "                                verbose=1)\n",
    "    grid_search.fit(X_train, y_train.ravel())\n",
    "    \n",
    "    print(f'\\tbest score: {grid_search.best_score_:.3f}')\n",
    "    print('\\tbest params')\n",
    "    pprint.pprint(grid_search.best_params_)\n",
    "    \n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    test_acc = accuracy_score(y_test, y_pred)\n",
    "    print(f'accuracy = {test_acc * 100}')\n",
    "    \n",
    "    print('-' * 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(129, 26)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, input_dim=26, activation='relu'))\n",
    "    model.add(Dense(26, activation='relu'))\n",
    "    model.add(Dense(26, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "NN = KerasClassifier(build_fn=create_model,\n",
    "                     epochs=10,\n",
    "                     batch_size=10,\n",
    "                     verbose=1)\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
    "results = cross_val_score(NN, X, y, cv=kfold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN.fit(X_train, y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fatigue",
   "language": "python",
   "name": "fatigue"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
